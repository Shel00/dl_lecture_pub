{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第6回演習課題"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1．convとdownsampleの使い方"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 畳み込みのフィルタ（重み）$W_{i,j}^{k,l}$\n",
    "    - 次元数4$(k,l,i,j)$\n",
    "        - $l$：入力のチャネル数\n",
    "        - $k$：フィルタ数（出力のチャネル数)\n",
    "        - $i$：フィルタの行数\n",
    "        - $j$：フィルタの列数\n",
    "    - ストライド：フィルタを適用する位置の間隔（theanoのsubsampleオプション）\n",
    "    - ゼロパディング：入力の周りに値0の縁を加える（theanoのborder_mode=\"full\"オプション）\n",
    "        - 入力のサイズを保つ為，フィルタの縦or横の次元が$F$のときパディング数を$(F-1)/2$とする．\n",
    "        - ただしborder_mode=\"full\"だと，$F-1$となることに注意\n",
    "- 入力または隠れ層$X_{i,j}^{k}$\n",
    "    - 次元数4$(n,k,i,j)$\n",
    "        - $n$：バッチサイズ\n",
    "        - $k$：チャネル数\n",
    "        - $i$：入力の行数\n",
    "        - $j$：入力の列数\n",
    "- フィルタ後のサイズは，入力の縦or横の次元数$N$，フィルタの縦or横の次元数$F$，ストライドの縦or横の量$S$で決まる．\n",
    "    - $(N-F)/S+1$\n",
    "    - border_mode=\"full\"の場合，S=1のとき$(N-F+2(F-1))+1=N+F-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  1.  1.  0.  0.]\n",
      " [ 0.  1.  1.  1.  0.]\n",
      " [ 0.  0.  1.  1.  1.]\n",
      " [ 0.  0.  1.  1.  0.]\n",
      " [ 0.  1.  1.  0.  0.]]\n",
      "[[ 4.  3.  4.]\n",
      " [ 2.  4.  3.]\n",
      " [ 2.  3.  4.]]\n",
      "[[ 4.  4.]\n",
      " [ 2.  4.]]\n",
      "[[ 1.  1.  2.  1.  1.  0.  0.]\n",
      " [ 0.  2.  2.  3.  1.  1.  0.]\n",
      " [ 1.  1.  4.  3.  4.  1.  1.]\n",
      " [ 0.  1.  2.  4.  3.  3.  0.]\n",
      " [ 0.  1.  2.  3.  4.  1.  1.]\n",
      " [ 0.  0.  2.  2.  1.  1.  0.]\n",
      " [ 0.  1.  1.  1.  1.  0.  0.]]\n",
      "[[ 4.  3.  4.  1.  1.]\n",
      " [ 2.  4.  3.  3.  0.]\n",
      " [ 2.  3.  4.  1.  1.]\n",
      " [ 2.  2.  1.  1.  0.]\n",
      " [ 1.  1.  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from theano.tensor.nnet import conv\n",
    "\n",
    "#入力 (バッチサイズとチャネル数は1）\n",
    "x = T.fmatrix('x')\n",
    "x_4d = x[np.newaxis,np.newaxis,:,:]\n",
    "#x_4d = x.dimshuffle('x','x',0,1)でも可\n",
    "\n",
    "#フィルタ(1,1,3,1)\n",
    "W = np.array([[1,0,1],[0,1,0],[1,0,1]]).astype(\"float32\").reshape(1, 1, 3, 3)\n",
    "\n",
    "#畳み込み((5-3)+1=3)\n",
    "convoluted_image = conv.conv2d(x_4d, W, border_mode=\"valid\")\n",
    "\n",
    "#ストライド(2×2)((5-3)/2+1=2)\n",
    "stride_convoluted_image = conv.conv2d(x_4d, W, border_mode=\"valid\",subsample=(2, 2))\n",
    "\n",
    "#パディング(full)((5+3)-1=7)\n",
    "fullpadding_convoluted_image = conv.conv2d(x_4d, W, border_mode=\"full\")\n",
    "\n",
    "#パディング(same size)\n",
    "pd_h = W.shape[2]-1\n",
    "pd_w = W.shape[3]-1\n",
    "x_h = x_4d.shape[2]\n",
    "x_w = x_4d.shape[3]\n",
    "samepadding_convoluted_image = conv.conv2d(x_4d, W, border_mode=\"full\")[:,:,pd_h:x_h+pd_h,pd_w:x_w+pd_w]\n",
    "\n",
    "#Convolution Function\n",
    "convolution = theano.function([x], convoluted_image)\n",
    "stride_convolution = theano.function([x], stride_convoluted_image)\n",
    "fullpadding_convolution = theano.function([x], fullpadding_convoluted_image)\n",
    "samepadding_convolution = theano.function([x], samepadding_convoluted_image)\n",
    "\n",
    "#Sample Image (5×5)\n",
    "sample_image = np.array([[1., 1., 1., 0., 0.], \n",
    "                         [0., 1., 1., 1., 0.], \n",
    "                         [0., 0., 1., 1., 1.], \n",
    "                         [0., 0., 1., 1., 0.], \n",
    "                         [0., 1., 1., 0., 0.]]).astype(\"float32\")\n",
    "\n",
    "#Original Image\n",
    "print sample_image\n",
    "\n",
    "#Convolved Image\n",
    "print convolution(sample_image).reshape(3, 3)\n",
    "print stride_convolution(sample_image).reshape(2, 2)\n",
    "print fullpadding_convolution(sample_image).reshape(7, 7)\n",
    "print samepadding_convolution(sample_image).reshape(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- プーリングには次の種類がある\n",
    "    - Max pooling (theanoでは'max')\n",
    "    - Sum pooling (theanoでは'sum')\n",
    "    - Mean pooling (theanoでは'average_exc_pad')\n",
    "    - その他Lpプーリングなど(theano未実装)\n",
    "- Convと同様，ストライドやパディングも考えることもある．\n",
    "    - ストライドはデフォルトではdsと同じ\n",
    "- ignore_border=Falseにすると，画像領域を超える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83.  83.]\n",
      " [ 87.  85.]]\n",
      "[[ 83.  82.  83.  83.]\n",
      " [ 87.  82.  83.  83.]\n",
      " [ 87.  87.  85.  80.]\n",
      " [ 87.  87.  85.  78.]]\n",
      "[[ 77.  82.  78.]\n",
      " [ 87.  82.  83.]\n",
      " [ 87.  87.  78.]]\n"
     ]
    }
   ],
   "source": [
    "from theano.tensor.signal import downsample\n",
    "\n",
    "#入力 (バッチサイズとチャネル数は1）\n",
    "x = T.fmatrix('x')\n",
    "x_4d = x[np.newaxis,np.newaxis,:,:]\n",
    "#x_4d = x.dimshuffle('x','x',0,1)でも可\n",
    "\n",
    "#pooling\n",
    "pooled = downsample.max_pool_2d(input=x_4d, ds=(2,2), ignore_border=True)\n",
    "\n",
    "#ストライド(1×1，デフォルトではdsと同じ）\n",
    "stride_pooled = downsample.max_pool_2d(input=x_4d, ds=(2,2), st=(1,1), ignore_border=True)\n",
    "\n",
    "#パディング\n",
    "padding_pooled = downsample.max_pool_2d(input=x_4d, ds=(2,2), ignore_border=True, padding=(1,1))\n",
    "\n",
    "#mean pooling\n",
    "#mean_pooled = downsample.max_pool_2d(input=x_4d, ds=(2,2), mode='average_exc_pad', ignore_border=True)\n",
    "\n",
    "#Pooling Function\n",
    "pooling = theano.function([x], pooled)\n",
    "stride_pooling = theano.function([x], stride_pooled)\n",
    "padding_pooling = theano.function([x], padding_pooled)\n",
    "#mean_pooling = theano.function([x], mean_pooled)\n",
    "\n",
    "#Sample Image (5×5)\n",
    "sample_image = np.array([[77, 80, 82, 78, 70], \n",
    "                         [83, 78, 80, 83, 82], \n",
    "                         [87, 82, 81, 80, 74], \n",
    "                         [87, 87, 85, 77, 66], \n",
    "                         [84, 79, 77, 78, 76]]).astype(\"float32\")\n",
    "\n",
    "print pooling(sample_image).reshape(2, 2)\n",
    "print stride_pooling(sample_image).reshape(4, 4)\n",
    "print padding_pooling(sample_image).reshape(3, 3)\n",
    "#print mean_pooling(sample_image).reshape(2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2．Conv layerとPooling layerの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from theano.tensor.nnet import conv\n",
    "class Conv:\n",
    "    def __init__(self,filter_shape,function,border_mode=\"valid\",subsample=(1, 1)):\n",
    "        \n",
    "        self.function = function\n",
    "        self.border_mode = border_mode\n",
    "        self.subsample = subsample\n",
    "        \n",
    "        fan_in = np.prod(filter_shape[1:])\n",
    "        fan_out = (filter_shape[0] * np.prod(filter_shape[2:]))\n",
    "        \n",
    "        self.W = theano.shared(rng.uniform(\n",
    "                    low=-4*np.sqrt(6. / (fan_in + fan_out)),\n",
    "                    high=4*np.sqrt(6. / (fan_in + fan_out)),\n",
    "                    size=filter_shape\n",
    "                ).astype(\"float32\"),name=\"W\")\n",
    "        #バイアスはフィルタごと\n",
    "        self.b = theano.shared(np.zeros((filter_shape[0],), dtype=\"float32\"),name=\"b\")\n",
    "        self.params = [self.W,self.b]\n",
    "        \n",
    "    def fprop(self,x):\n",
    "        #畳込み処理\n",
    "        conv_out = conv.conv2d(x,self.W,\n",
    "                               border_mode=self.border_mode,\n",
    "                               subsample=self.subsample)\n",
    "        #バイアスを加えて（第1要素）活性化関数をかける\n",
    "        y = self.function(conv_out + self.b[np.newaxis,:,np.newaxis,np.newaxis])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from theano.tensor.signal import downsample\n",
    "class Pooling:\n",
    "    def __init__(self,pool_size=(2,2)):\n",
    "        self.pool_size=pool_size\n",
    "        self.params = []\n",
    "    def fprop(self,x):\n",
    "        #プーリングした値を返す\n",
    "        return downsample.max_pool_2d(x,self.pool_size,ignore_border=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def __init__(self,outdim=2):\n",
    "        self.outdim = outdim\n",
    "        self.params = []\n",
    "    def fprop(self,x):\n",
    "        #flattenはoutdim次元にする関数\n",
    "        return T.flatten(x,self.outdim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題．畳み込みニューラルネットワークの実装，MNISTでの実験．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データはmnist_x,mnist_yで与えられます\n",
    "    - mnsit_xとmnist_yをtrain_X,train_yとvalid_X,valid_yに分けるなどしてモデルを学習してください\n",
    "- test関数を定義してください\n",
    "    - 採点システム側で用意したtest_Xを与えたときの出力の精度(F値)で評価します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from collections import OrderedDict\n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist_x, mnist_y = mnist.data.astype(\"float32\")/255.0, mnist.target.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルを完成させて提出してください\n",
    "- レイヤークラスなど，必要なものは全て書いてください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data... Done\n",
      "Setting up layers...\n",
      "Done\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('An update must have the same type as the original shared variable (shared_var=W, shared_var.type=TensorType(float32, 4D), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, 4D)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-ffe5beffa445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0mvalid\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0mtest\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/takuma7/.pyenv/versions/2.7.10/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m                 profile=profile)\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;31m# borrowed used defined inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/takuma7/.pyenv/versions/2.7.10/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[0;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[1;32m    487\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[1;32m    490\u001b[0m     \u001b[0;31m# extracting the arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcloned_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/takuma7/.pyenv/versions/2.7.10/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[0;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[1;32m    215\u001b[0m                        ' function to remove broadcastable dimensions.')\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_sug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mupdate_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstore_into\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('An update must have the same type as the original shared variable (shared_var=W, shared_var.type=TensorType(float32, 4D), update_val=Elemwise{sub,no_inplace}.0, update_val.type=TensorType(float64, 4D)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')"
     ]
    }
   ],
   "source": [
    "#SGD\n",
    "def sgd(params,gparams,lr=0.1):\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        updates[param] = (param - lr * gparam).astype(\"float32\")\n",
    "    return updates\n",
    "\n",
    "#Layer \n",
    "class Layer:\n",
    "    def __init__(self, in_dim, out_dim, function):\n",
    "        ## WRITE ME Done\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.function = function\n",
    "        self.W = theano.shared(\n",
    "                                rng.uniform(\n",
    "                                            low=-0.08, \n",
    "                                            high=0.08, \n",
    "                                            size=(in_dim, out_dim)\n",
    "                                ).astype(\"float32\"), name=\"W\")\n",
    "        self.b =  theano.shared(np.zeros(out_dim).astype(\"float32\"), name=\"bias\")\n",
    "        \n",
    "        self.params = [ self.W, self.b ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        ## WRITE ME Done\n",
    "        h = self.function(T.dot(x, self.W)+self.b)\n",
    "        self.h = h\n",
    "        return self.h\n",
    "\n",
    "    \n",
    "#Conv layer\n",
    "from theano.tensor.nnet import conv\n",
    "class Conv:\n",
    "    def __init__(self,filter_shape,function,border_mode=\"valid\",subsample=(1, 1)):\n",
    "        \n",
    "        self.function = function\n",
    "        self.border_mode = border_mode\n",
    "        self.subsample = subsample\n",
    "        \n",
    "        fan_in = np.prod(filter_shape[1:])\n",
    "        fan_out = (filter_shape[0] * np.prod(filter_shape[2:]))\n",
    "        \n",
    "        self.W = theano.shared(rng.uniform(\n",
    "                    low=-4*np.sqrt(6. / (fan_in + fan_out)),\n",
    "                    high=4*np.sqrt(6. / (fan_in + fan_out)),\n",
    "                    size=filter_shape\n",
    "                ).astype(\"float32\"),name=\"W\")\n",
    "        #バイアスはフィルタごと\n",
    "        self.b = theano.shared(np.zeros((filter_shape[0],), dtype=\"float32\"),name=\"b\")\n",
    "        self.params = [self.W,self.b]\n",
    "        \n",
    "    def fprop(self,x):\n",
    "        #畳込み処理\n",
    "        conv_out = conv.conv2d(x,self.W,\n",
    "                               border_mode=self.border_mode,\n",
    "                               subsample=self.subsample)\n",
    "        #バイアスを加えて（第1要素）活性化関数をかける\n",
    "        y = self.function(conv_out + self.b[np.newaxis,:,np.newaxis,np.newaxis])\n",
    "        return y\n",
    "\n",
    "#Pooling layer\n",
    "from theano.tensor.signal import downsample\n",
    "class Pooling:\n",
    "    def __init__(self,pool_size=(2,2)):\n",
    "        self.pool_size=pool_size\n",
    "        self.params = []\n",
    "    def fprop(self,x):\n",
    "        #プーリングした値を返す\n",
    "        return downsample.max_pool_2d(x,self.pool_size,ignore_border=True)\n",
    "#Flatten layer\n",
    "class Flatten:\n",
    "    def __init__(self,outdim=2):\n",
    "        self.outdim = outdim\n",
    "        self.params = []\n",
    "    def fprop(self,x):\n",
    "        #flattenはoutdim次元にする関数\n",
    "        return T.flatten(x,self.outdim)\n",
    "\n",
    "print \"Setting up data...\",\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(mnist_x, mnist_y, test_size=0.2, random_state=42)\n",
    "print \"Done\"\n",
    "\n",
    "print \"Setting up layers...\",\n",
    "activation = T.nnet.sigmoid\n",
    "layers = [\n",
    "    Conv((20,1,5,5),activation),\n",
    "    Pooling((2,2)),\n",
    "    Conv((50,20,5,5),activation),\n",
    "    Pooling((2,2)),\n",
    "    Flatten(2),\n",
    "    Layer(800,500, activation),#800=((((28-5+1)/2)-5+1)/2)**2*50\n",
    "    Layer(500,10, T.nnet.softmax)\n",
    "]\n",
    "print \"Done\"\n",
    "\n",
    "x, t = T.fmatrix(\"x\"), T.ivector(\"t\")\n",
    "x_4d = x.reshape((x.shape[0],1,28,28)) #画像を4次元にする\n",
    "\n",
    "params = []\n",
    "layer_out = x_4d\n",
    "for i, layer in enumerate(layers):\n",
    "    params += layer.params\n",
    "    layer_out = layer.fprop(layer_out)\n",
    "\n",
    "y = layers[-1].h\n",
    "cost = - T.mean((T.log(y))[T.arange(x.shape[0]), t])\n",
    "\n",
    "gparams = T.grad(cost, params)\n",
    "updates = sgd(params,gparams)\n",
    "\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "valid  = theano.function([x,t],[cost, T.argmax(y, axis=1)])\n",
    "test  = theano.function([x],T.argmax(y, axis=1))\n",
    "\n",
    "##以下は通常のMLPと同じ実装で訓練\n",
    "print \"Start Training\"\n",
    "batch_size = 100\n",
    "nbatches = train_X.shape[0]//batch_size\n",
    "for epoch in range(50):\n",
    "    ## WRITE ME\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i in range(nbatches):\n",
    "            start = i * batch_size\n",
    "            end = start + batch_size\n",
    "            train(train_X[start:end], train_y[start:end])\n",
    "    valid_cost, pred = valid(valid_X, valid_y)\n",
    "\n",
    "    print \"EPOCH:: %i, Validation cost: %.3f, Validation F1: %.3f\"%(epoch+1, valid_cost, f1_score(valid_y, pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の処理は，システム側で行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_y = test(test_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
